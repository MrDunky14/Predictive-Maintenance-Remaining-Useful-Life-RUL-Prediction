{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Useful Life (RUL) Prediction for a Single Engine\n",
    "\n",
    "This notebook demonstrates how to use a pre-trained LSTM model to predict the Remaining Useful Life (RUL) for a single turbofan engine's sensor data. It replicates the necessary preprocessing steps from the original training pipeline to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Pre-trained Assets\n",
    "\n",
    "We'll start by importing all the necessary libraries and loading the pre-trained LSTM model and the scalers (for features and RUL) that were saved during the model training phase in `PMIE.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LSTM model.\n",
      "Successfully loaded feature and RUL scalers.\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">597,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">185,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">471,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m416\u001b[0m)        │       \u001b[38;5;34m597,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m416\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m185,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m198,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │       \u001b[38;5;34m471,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,359,173</span> (16.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,359,173\u001b[0m (16.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,453,057</span> (5.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,453,057\u001b[0m (5.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,906,116</span> (11.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,906,116\u001b[0m (11.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%run custom_functions.py # Runs the whole custom_function to get all functions/classes in the notebook\n",
    "\n",
    "# --- Load the pre-trained model and scalers ---\n",
    "try:\n",
    "    LTSM_model = tf.keras.models.load_model('model/final_lstm_model.keras') # Or 'best_model.keras'\n",
    "    print(\"Successfully loaded LSTM model.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}. Make sure 'final_lstm_model.keras' (or 'best_model.keras') is in the correct directory.\")\n",
    "    # Fallback to .h5 if .keras fails, though .keras is preferred\n",
    "    try:\n",
    "        LTSM_model = tf.keras.models.load_model('final_lstm_model.h5')\n",
    "        print(\"Successfully loaded LSTM model from .h5 fallback.\")\n",
    "    except Exception as e_h5:\n",
    "        print(f\"Error loading .h5 model: {e_h5}. Please ensure your model file exists.\")\n",
    "        LTSM_model = None # Set to None to prevent further errors\n",
    "\n",
    "try:\n",
    "    feature_scaler = joblib.load('feature_scaler.pkl')\n",
    "    rul_scaler = joblib.load('rul_scaler.pkl')\n",
    "    print(\"Successfully loaded feature and RUL scalers.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading scalers: {e}. Make sure 'feature_scaler.pkl' and 'rul_scaler.pkl' are in the correct directory.\")\n",
    "    feature_scaler = None\n",
    "    rul_scaler = None\n",
    "\n",
    "# Define the sequence length (hyperparameter) - must match training\n",
    "sequence_length = 30\n",
    "\n",
    "if LTSM_model:\n",
    "    print(\"\\nModel Summary:\")\n",
    "    LTSM_model.summary()\n",
    "else:\n",
    "    print(\"\\nModel not loaded. Cannot show summary or proceed with prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Single Engine Data\n",
    "\n",
    "We will load the `test_FD002.txt` dataset and select data for a specific `engine_id`. This data will then undergo the same preprocessing steps as the training data: dropping constant columns, scaling, and generating rolling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded raw test data.\n",
      "\n",
      "Data for Engine ID 141 (first 5 rows):\n",
      "        engine_id  cycle  op_setting_1  op_setting_2  op_setting_3  sensor_1  \\\n",
      "19011        141      1       20.0046        0.7014         100.0    491.19   \n",
      "19012        141      2        0.0002        0.0015         100.0    518.67   \n",
      "19013        141      3       25.0010        0.6200          60.0    462.54   \n",
      "19014        141      4       10.0026        0.2500         100.0    489.05   \n",
      "19015        141      5       10.0020        0.2500         100.0    489.05   \n",
      "\n",
      "       sensor_2  sensor_3  sensor_4  sensor_5  ...  sensor_11  sensor_12  \\\n",
      "19011    607.12   1483.99   1250.80      9.35  ...      44.34     315.66   \n",
      "19012    642.92   1589.91   1406.07     14.62  ...      47.25     522.19   \n",
      "19013    536.74   1264.53   1034.97      7.05  ...      36.80     164.84   \n",
      "19014    604.63   1508.43   1304.44     10.52  ...      45.22     371.88   \n",
      "19015    604.31   1497.23   1304.99     10.52  ...      45.15     371.95   \n",
      "\n",
      "       sensor_13  sensor_14  sensor_15  sensor_17  sensor_18  sensor_19  \\\n",
      "19011    2388.05    8060.68     9.2036        365       2324     100.00   \n",
      "19012    2388.06    8138.18     8.3924        390       2388     100.00   \n",
      "19013    2028.26    7879.21    10.8774        307       1915      84.93   \n",
      "19014    2388.09    8127.08     8.6524        370       2319     100.00   \n",
      "19015    2388.06    8130.58     8.6427        369       2319     100.00   \n",
      "\n",
      "       sensor_20  sensor_21  \n",
      "19011      24.59    14.7055  \n",
      "19012      38.97    23.3644  \n",
      "19013      14.38     8.6192  \n",
      "19014      28.70    17.1057  \n",
      "19015      28.60    17.1625  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Total cycles for Engine ID 141: 69\n",
      "\n",
      "Features scaled for single engine data.\n",
      "\n",
      "Generating rolling features with window size 30...\n",
      "\n",
      "Single engine data after rolling features (last 5 rows):\n",
      "        engine_id     cycle  op_setting_1  op_setting_2  op_setting_3  \\\n",
      "19075        141  0.118081      0.238062      0.296912           1.0   \n",
      "19076        141  0.119926      0.595244      0.737173           0.0   \n",
      "19077        141  0.121771      0.476093      0.831354           1.0   \n",
      "19078        141  0.123616      0.000062      0.000000           1.0   \n",
      "19079        141  0.125461      0.999910      0.999406           1.0   \n",
      "\n",
      "       sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  ...  \\\n",
      "19075  0.597937  0.638206  0.695326  0.666499  0.617180  ...   \n",
      "19076  0.238089  0.010180  0.057219  0.033669  0.293184  ...   \n",
      "19077  0.626985  0.658657  0.630303  0.539496  0.507937  ...   \n",
      "19078  1.000000  0.982300  0.922745  0.930024  1.000000  ...   \n",
      "19079  0.000000  0.128302  0.300813  0.237794  0.000000  ...   \n",
      "\n",
      "       sensor_17_rolling_mean_30  sensor_17_rolling_std_30  \\\n",
      "19075                   0.581100                  0.321896   \n",
      "19076                   0.573883                  0.330976   \n",
      "19077                   0.574227                  0.331052   \n",
      "19078                   0.603780                  0.321260   \n",
      "19079                   0.592440                  0.325566   \n",
      "\n",
      "       sensor_18_rolling_mean_30  sensor_18_rolling_std_30  \\\n",
      "19075                   0.721142                  0.349635   \n",
      "19076                   0.700211                  0.373396   \n",
      "19077                   0.700211                  0.373396   \n",
      "19078                   0.733545                  0.352799   \n",
      "19079                   0.725652                  0.352412   \n",
      "\n",
      "       sensor_19_rolling_mean_30  sensor_19_rolling_std_30  \\\n",
      "19075                   0.833333                  0.379049   \n",
      "19076                   0.800000                  0.406838   \n",
      "19077                   0.800000                  0.406838   \n",
      "19078                   0.833333                  0.379049   \n",
      "19079                   0.833333                  0.379049   \n",
      "\n",
      "       sensor_20_rolling_mean_30  sensor_20_rolling_std_30  \\\n",
      "19075                   0.529039                  0.352924   \n",
      "19076                   0.533176                  0.347322   \n",
      "19077                   0.532986                  0.347350   \n",
      "19078                   0.560567                  0.347748   \n",
      "19079                   0.545386                  0.361190   \n",
      "\n",
      "       sensor_21_rolling_mean_30  sensor_21_rolling_std_30  \n",
      "19075                   0.533347                  0.354059  \n",
      "19076                   0.537768                  0.348101  \n",
      "19077                   0.537842                  0.348090  \n",
      "19078                   0.565140                  0.348411  \n",
      "19079                   0.549629                  0.362248  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "Total features for prediction: 61\n",
      "Expected number of features by model: 61\n"
     ]
    }
   ],
   "source": [
    "# Load the raw test data\n",
    "try:\n",
    "    test_df_raw = import_data('test/test_FD002.txt')\n",
    "    print(\"Successfully loaded raw test data.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading 'test_FD002.txt': {e}. Please ensure the file is in the correct directory.\")\n",
    "    test_df_raw = pd.DataFrame() # Create an empty DataFrame to prevent further errors\n",
    "\n",
    "if not test_df_raw.empty:\n",
    "    # Choose an engine ID for prediction\n",
    "    # You can change this to any engine ID present in your test_FD003.txt\n",
    "    # For example, engine 10 has fewer cycles, which might trigger a warning.\n",
    "    target_engine_id = 141 # Example: Engine ID 1\n",
    "\n",
    "    # Extract data for the chosen engine\n",
    "    single_engine_df = test_df_raw[test_df_raw['engine_id'] == target_engine_id].copy()\n",
    "\n",
    "    if single_engine_df.empty:\n",
    "        print(f\"Error: No data found for Engine ID {target_engine_id}. Please choose a valid engine ID.\")\n",
    "    else:\n",
    "        print(f\"\\nData for Engine ID {target_engine_id} (first 5 rows):\\n\", single_engine_df.head())\n",
    "        print(f\"Total cycles for Engine ID {target_engine_id}: {len(single_engine_df)}\")\n",
    "\n",
    "        # Define feature columns (must match the features used during training)\n",
    "        # This list should be exactly what `feature_cols` was in PMIE.ipynb after dropping const_col\n",
    "        # and before adding rolling features.\n",
    "        initial_feature_cols = [col for col in single_engine_df.columns if col not in ['engine_id']]\n",
    "\n",
    "        # Apply feature scaling using the loaded feature_scaler\n",
    "        if feature_scaler:\n",
    "            single_engine_df[initial_feature_cols] = feature_scaler.transform(single_engine_df[initial_feature_cols])\n",
    "            print(\"\\nFeatures scaled for single engine data.\")\n",
    "        else:\n",
    "            print(\"\\nFeature scaler not loaded. Skipping feature scaling.\")\n",
    "\n",
    "        # --- Generate Rolling Features (must match training parameters) ---\n",
    "        window_size = 30 # Must match the window_size used in training\n",
    "        selected_sensors = [col for col in initial_feature_cols if col not in ['op_setting_1','op_setting_2','op_setting_3','cycle']]\n",
    "\n",
    "        print(f\"\\nGenerating rolling features with window size {window_size}...\")\n",
    "\n",
    "        for sensor in selected_sensors:\n",
    "            # Rolling mean\n",
    "            single_engine_df[f'{sensor}_rolling_mean_{window_size}'] = single_engine_df[sensor].rolling(window=window_size, min_periods=1).mean()\n",
    "            # Rolling standard deviation\n",
    "            single_engine_df[f'{sensor}_rolling_std_{window_size}'] = single_engine_df[sensor].rolling(window=window_size, min_periods=1).std()\n",
    "\n",
    "        # Handle NaNs in rolling features (bfill then ffill, as in PMIE.ipynb)\n",
    "        for sensor in selected_sensors:\n",
    "            single_engine_df[f'{sensor}_rolling_std_{window_size}'] = single_engine_df[f'{sensor}_rolling_std_{window_size}'].bfill().ffill()\n",
    "\n",
    "        # Update feature_cols to include all raw and rolling features\n",
    "        # This list should now contain all 48 features that the model expects\n",
    "        final_feature_cols = [col for col in single_engine_df.columns if col not in ['engine_id']]\n",
    "\n",
    "        print(f\"\\nSingle engine data after rolling features (last 5 rows):\\n\", single_engine_df.tail())\n",
    "        print(f\"Total features for prediction: {len(final_feature_cols)}\")\n",
    "        print(f\"Expected number of features by model: {LTSM_model.input_shape[2] if LTSM_model else 'N/A'}\")\n",
    "else:\n",
    "    print(\"Cannot proceed without raw test data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Sequence for Prediction\n",
    "\n",
    "Now, we'll use the `create_single_last_sequence` function to extract the final sequence of data for prediction. This sequence must have the correct 3D shape `(1, sequence_length, num_features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of input for prediction: (1, 30, 61)\n",
      "Expected model input shape: (None, 30, 61)\n",
      "Input shape matches model's expected input shape. Proceeding with prediction.\n"
     ]
    }
   ],
   "source": [
    "if not single_engine_df.empty and LTSM_model and feature_scaler and rul_scaler:\n",
    "    # Generate the single sequence for prediction\n",
    "    # The function returns a 2D array (sequence_length, num_features) or None\n",
    "    single_sequence = create_single_last_sequence(single_engine_df, sequence_length, final_feature_cols)\n",
    "\n",
    "    if single_sequence is not None:\n",
    "        # Reshape for the model: (1, sequence_length, num_features)\n",
    "        # The model expects a batch dimension, even for a single sample.\n",
    "        input_for_prediction = np.expand_dims(single_sequence, axis=0)\n",
    "\n",
    "        print(f\"\\nShape of input for prediction: {input_for_prediction.shape}\")\n",
    "        print(f\"Expected model input shape: {LTSM_model.input_shape}\")\n",
    "\n",
    "        if input_for_prediction.shape[1:] == LTSM_model.input_shape[1:]:\n",
    "            print(\"Input shape matches model's expected input shape. Proceeding with prediction.\")\n",
    "        else:\n",
    "            print(\"\\nERROR: Input shape does NOT match model's expected input shape. Check feature engineering and sequence generation.\")\n",
    "            input_for_prediction = None # Prevent prediction if shape is wrong\n",
    "    else:\n",
    "        print(\"\\nCould not generate a valid sequence for prediction (engine data too short).\")\n",
    "        input_for_prediction = None\n",
    "else:\n",
    "    print(\"\\nCannot prepare sequence. Ensure data, model, and scalers are loaded correctly.\")\n",
    "    input_for_prediction = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Prediction and Inverse Transform\n",
    "\n",
    "Finally, we'll use the loaded LSTM model to make a prediction on the prepared sequence and then inverse transform the result to get the RUL in its original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      "Predicted RUL (scaled): 0.2077\n",
      "Predicted RUL (original scale) for Engine ID 141: 112.57 cycles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751912247.851198    4979 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    }
   ],
   "source": [
    "if input_for_prediction is not None:\n",
    "    # Make the prediction\n",
    "    predicted_rul_scaled = LTSM_model.predict(input_for_prediction)\n",
    "\n",
    "    # Inverse transform the prediction to get the real RUL value\n",
    "    predicted_rul_original_scale = rul_scaler.inverse_transform(predicted_rul_scaled)\n",
    "\n",
    "    print(f\"\\nPredicted RUL (scaled): {predicted_rul_scaled[0][0]:.4f}\")\n",
    "    print(f\"Predicted RUL (original scale) for Engine ID {target_engine_id}: {predicted_rul_original_scale[0][0]:.2f} cycles\")\n",
    "else:\n",
    "    print(\"\\nPrediction skipped due to issues with data preparation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
